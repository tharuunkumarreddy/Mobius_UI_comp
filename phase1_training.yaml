name: phase1_training
display_name: Phase 1 Training (Category Classification)
description: Trains ResNet50 model for UI category classification with mixed precision

parameters:
  num_epochs:
    type: int
    default: 10
    validation:
      min: 1
      max: 200
    description: Number of training epochs
  
  learning_rate:
    type: float
    default: 3e-4
    validation:
      min: 1e-6
      max: 1e-1
    description: Initial learning rate
  
  weight_decay:
    type: float
    default: 1e-4
    validation:
      min: 0.0
      max: 1e-1
    description: Weight decay for regularization
  
  label_smoothing:
    type: float
    default: 0.05
    validation:
      min: 0.0
      max: 0.3
    description: Label smoothing factor
  
  warmup_ratio:
    type: float
    default: 0.05
    validation:
      min: 0.0
      max: 0.3
    description: Warmup ratio for learning rate scheduler
  
  output_dir:
    type: str
    default: "./phase1_resnet50"
    description: Directory to save model checkpoints
  
  save_every_n_epochs:
    type: int
    default: 5
    description: Save checkpoint every N epochs
  
  early_stopping_patience:
    type: int
    default: 0
    description: Early stopping patience (0 = disabled)
  
  gradient_clip_norm:
    type: float
    default: 1.0
    description: Gradient clipping norm (0 = disabled)
  
  mixed_precision:
    type: bool
    default: true
    description: Enable mixed precision training

inputs:
  model:
    type: object
    description: Initialized ResNet50 model
  
  train_loader:
    type: object
    description: Training data loader
  
  val_loader:
    type: object
    description: Validation data loader
  
  model_config:
    type: dict
    description: Model configuration parameters

outputs:
  trained_model:
    type: file
    format: pt
    description: Best trained model checkpoint
    path: "{output_dir}/phase1_best.pt"
  
  final_model:
    type: file
    format: pt
    description: Final model checkpoint
    path: "{output_dir}/phase1_final.pt"
  
  training_history:
    type: file
    format: json
    description: Training history and metrics
    path: "{output_dir}/training_history.json"
  
  training_config:
    type: file
    format: json
    description: Training configuration used
    path: "{output_dir}/training_config.json"

code: |
  import os
  import json
  import math
  import time
  from pathlib import Path
  import torch
  import torch.nn as nn
  import torch.optim as optim
  import torch.nn.functional as F
  from torch.cuda.amp import GradScaler, autocast
  import matplotlib.pyplot as plt
  
  # Setup paths and device
  output_dir = Path(output_dir)
  output_dir.mkdir(parents=True, exist_ok=True)
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  
  # Get model configuration
  category_to_idx = model_config["category_to_idx"]
  idx_to_category = {i: cat for cat, i in category_to_idx.items()}
  
  print(f"Starting Phase 1 training on device: {device}")
  print(f"Model: {model_config['model_type']}")
  print(f"Categories: {model_config['num_categories']}")
  print(f"Training samples: {model_config.get('train_size', 'Unknown')}")
  print(f"Validation samples: {model_config.get('val_size', 'Unknown')}")
  
  # Training utilities
  def accuracy(outputs, targets):
      preds = outputs.argmax(dim=1)
      return (preds == targets).float().mean().item()
  
  def evaluate(model, loader, criterion, device, use_amp=True):
      model.eval()
      running_loss, running_acc, n = 0.0, 0.0, 0
      predictions, targets_list = [], []
      
      with torch.no_grad():
          for x, y in loader:
              x, y = x.to(device), y.to(device)
              
              if use_amp and device.type == 'cuda':
                  with autocast():
                      logits = model(x)
                      loss = criterion(logits, y)
              else:
                  logits = model(x)
                  loss = criterion(logits, y)
              
              bs = y.size(0)
              running_loss += loss.item() * bs
              running_acc += accuracy(logits, y) * bs
              n += bs
              
              # Store predictions for detailed analysis
              preds = logits.argmax(dim=1).cpu().numpy()
              predictions.extend(preds)
              targets_list.extend(y.cpu().numpy())
      
      return running_loss / n, running_acc / n, predictions, targets_list
  
  def save_checkpoint(model, optimizer, scheduler, epoch, val_acc, filepath, config):
      """Save comprehensive checkpoint"""
      checkpoint = {
          "model_state": model.state_dict(),
          "optimizer_state": optimizer.state_dict(),
          "scheduler_state": scheduler.state_dict() if scheduler else None,
          "epoch": epoch,
          "val_acc": val_acc,
          "model_config": config,
          "category_to_idx": category_to_idx,
          "idx_to_category": idx_to_category,
          "image_size": 224
      }
      torch.save(checkpoint, filepath)
  
  def calculate_class_weights(train_loader, num_classes):
      """Calculate class weights for imbalanced datasets"""
      class_counts = torch.zeros(num_classes)
      total_samples = 0
      
      for _, targets in train_loader:
          for target in targets:
              class_counts[target] += 1
              total_samples += 1
      
      # Inverse frequency weighting
      class_weights = total_samples / (num_classes * class_counts)
      class_weights = class_weights / class_weights.sum() * num_classes  # Normalize
      
      return class_weights
  
  # Calculate class weights for imbalanced dataset handling
  print("Calculating class weights...")
  class_weights = calculate_class_weights(train_loader, model_config["num_categories"])
  print(f"Class weights range: [{class_weights.min():.3f}, {class_weights.max():.3f}]")
  
  # Setup loss, optimizer, and scheduler
  criterion = nn.CrossEntropyLoss(
      label_smoothing=label_smoothing,
      weight=class_weights.to(device) if torch.cuda.is_available() else class_weights
  )
  
  optimizer = optim.AdamW(
      model.parameters(), 
      lr=learning_rate, 
      weight_decay=weight_decay,
      betas=(0.9, 0.999),
      eps=1e-8
  )
  
  # Cosine decay + warmup scheduler
  total_steps = num_epochs * len(train_loader)
  warmup_steps = max(100, int(warmup_ratio * total_steps))
  
  def lr_lambda(step):
      if step < warmup_steps:
          return float(step) / float(max(1, warmup_steps))
      progress = (step - warmup_steps) / float(max(1, total_steps - warmup_steps))
      return 0.5 * (1.0 + math.cos(math.pi * progress))
  
  scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
  
  # Mixed precision scaler
  scaler = GradScaler() if mixed_precision and device.type == 'cuda' else None
  
  # Training state
  best_val_acc = 0.0
  best_epoch = 0
  patience_counter = 0
  
  training_history = {
      "train_loss": [],
      "train_acc": [],
      "val_loss": [],
      "val_acc": [],
      "learning_rate": [],
      "epoch_times": []
  }
  
  # Save training configuration
  training_config = {
      "num_epochs": num_epochs,
      "learning_rate": learning_rate,
      "weight_decay": weight_decay,
      "label_smoothing": label_smoothing,
      "warmup_ratio": warmup_ratio,
      "batch_size": train_loader.batch_size,
      "mixed_precision": mixed_precision,
      "gradient_clip_norm": gradient_clip_norm,
      "early_stopping_patience": early_stopping_patience,
      "optimizer": "AdamW",
      "scheduler": "CosineAnnealingLR",
      "criterion": "CrossEntropyLoss",
      "device": str(device),
      "model_config": model_config
  }
  
  with open(output_dir / "training_config.json", "w") as f:
      json.dump(training_config, f, indent=2)
  
  print("\n" + "="*60)
  print("STARTING TRAINING")
  print("="*60)
  
  # Training loop
  global_step = 0
  
  for epoch in range(1, num_epochs + 1):
      model.train()
      epoch_loss, epoch_acc, seen = 0.0, 0.0, 0
      t0 = time.time()
  
      for batch_idx, (x, y) in enumerate(train_loader):
          x, y = x.to(device), y.to(device)
          optimizer.zero_grad(set_to_none=True)
  
          # Forward pass with optional mixed precision
          if mixed_precision and scaler:
              with autocast():
                  logits = model(x)
                  loss = criterion(logits, y)
              
              # Backward pass
              scaler.scale(loss).backward()
              
              # Gradient clipping
              if gradient_clip_norm > 0:
                  scaler.unscale_(optimizer)
                  torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_norm)
              
              scaler.step(optimizer)
              scaler.update()
          else:
              logits = model(x)
              loss = criterion(logits, y)
              loss.backward()
              
              # Gradient clipping
              if gradient_clip_norm > 0:
                  torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_norm)
              
              optimizer.step()

          scheduler.step()
          
          # Statistics
          bs = y.size(0)
          epoch_loss += loss.item() * bs
          epoch_acc += accuracy(logits, y) * bs
          seen += bs
          global_step += 1
          
          # Log progress
          if (batch_idx + 1) % 50 == 0:
              current_lr = scheduler.get_last_lr()[0]
              print(f"  Epoch {epoch:2d} [{batch_idx+1:4d}/{len(train_loader)}] | "
                    f"Loss: {loss.item():.4f} | LR: {current_lr:.6f}")

      # Calculate epoch metrics
      train_loss = epoch_loss / seen
      train_acc = epoch_acc / seen
      current_lr = scheduler.get_last_lr()[0]
      
      # Validation
      val_loss, val_acc, val_preds, val_targets = evaluate(
          model, val_loader, criterion, device, mixed_precision
      )
      
      epoch_time = time.time() - t0
      
      # Store metrics
      training_history["train_loss"].append(train_loss)
      training_history["train_acc"].append(train_acc)
      training_history["val_loss"].append(val_loss)
      training_history["val_acc"].append(val_acc)
      training_history["learning_rate"].append(current_lr)
      training_history["epoch_times"].append(epoch_time)

      # Print epoch summary
      print(f"\nEpoch {epoch:2d}/{num_epochs} | {epoch_time:.1f}s")
      print(f"  Train: loss={train_loss:.4f}, acc={train_acc:.3f}")
      print(f"  Val:   loss={val_loss:.4f}, acc={val_acc:.3f}")
      print(f"  LR: {current_lr:.6f}")

      # Save best model
      if val_acc > best_val_acc:
          best_val_acc = val_acc
          best_epoch = epoch
          patience_counter = 0
          
          best_model_path = output_dir / "phase1_best.pt"
          save_checkpoint(model, optimizer, scheduler, epoch, val_acc, 
                         best_model_path, model_config)
          print(f"  ✅ New best model saved! Val acc: {val_acc:.3f}")
      else:
          patience_counter += 1

      # Save periodic checkpoint
      if save_every_n_epochs > 0 and epoch % save_every_n_epochs == 0:
          periodic_path = output_dir / f"phase1_epoch_{epoch}.pt"
          save_checkpoint(model, optimizer, scheduler, epoch, val_acc,
                         periodic_path, model_config)
          print(f"  💾 Periodic checkpoint saved")

      # Early stopping check
      if early_stopping_patience > 0 and patience_counter >= early_stopping_patience:
          print(f"\n⏹️  Early stopping triggered after {patience_counter} epochs without improvement")
          break

  # Save final model
  final_model_path = output_dir / "phase1_final.pt"
  save_checkpoint(model, optimizer, scheduler, epoch, val_acc,
                 final_model_path, model_config)

  # Enhanced training history with analysis
  training_history["training_summary"] = {
      "total_epochs": epoch,
      "best_epoch": best_epoch,
      "best_val_acc": best_val_acc,
      "final_val_acc": val_acc,
      "total_training_time": sum(training_history["epoch_times"]),
      "avg_epoch_time": sum(training_history["epoch_times"]) / len(training_history["epoch_times"]),
      "early_stopped": patience_counter >= early_stopping_patience if early_stopping_patience > 0 else False
  }

  # Calculate per-category performance on validation set
  from collections import defaultdict
  category_performance = defaultdict(lambda: {"correct": 0, "total": 0})
  
  for pred, target in zip(val_preds, val_targets):
      category = idx_to_category[target]
      category_performance[category]["total"] += 1
      if pred == target:
          category_performance[category]["correct"] += 1

  category_accuracies = {}
  for category, stats in category_performance.items():
      accuracy = stats["correct"] / stats["total"] if stats["total"] > 0 else 0
      category_accuracies[category] = {
          "accuracy": accuracy,
          "correct": stats["correct"],
          "total": stats["total"]
      }

  training_history["category_performance"] = category_accuracies

  # Save comprehensive training history
  history_path = output_dir / "training_history.json"
  with open(history_path, "w") as f:
      json.dump(training_history, f, indent=2)

  # Generate training plots if matplotlib is available
  try:
      plt.figure(figsize=(15, 5))
      
      # Loss plot
      plt.subplot(1, 3, 1)
      plt.plot(training_history["train_loss"], label="Train Loss", color='blue')
      plt.plot(training_history["val_loss"], label="Val Loss", color='red')
      plt.title("Training and Validation Loss")
      plt.xlabel("Epoch")
      plt.ylabel("Loss")
      plt.legend()
      plt.grid(True)
      
      # Accuracy plot
      plt.subplot(1, 3, 2)
      plt.plot(training_history["train_acc"], label="Train Acc", color='blue')
      plt.plot(training_history["val_acc"], label="Val Acc", color='red')
      plt.title("Training and Validation Accuracy")
      plt.xlabel("Epoch")
      plt.ylabel("Accuracy")
      plt.legend()
      plt.grid(True)
      
      # Learning rate plot
      plt.subplot(1, 3, 3)
      plt.plot(training_history["learning_rate"], color='green')
      plt.title("Learning Rate Schedule")
      plt.xlabel("Epoch")
      plt.ylabel("Learning Rate")
      plt.grid(True)
      plt.yscale('log')
      
      plt.tight_layout()
      plt.savefig(output_dir / "training_plots.png", dpi=150, bbox_inches='tight')
      plt.close()
      
      print(f"📊 Training plots saved to: {output_dir}/training_plots.png")
      
  except Exception as e:
      print(f"Warning: Could not generate training plots: {e}")

  # Save additional label mappings for inference
  with open(output_dir / "category_to_idx.json", "w") as f:
      json.dump(category_to_idx, f, indent=2)
  with open(output_dir / "idx_to_category.json", "w") as f:
      json.dump(idx_to_category, f, indent=2)

  print("\n" + "="*60)
  print("TRAINING COMPLETE")
  print("="*60)
  print(f"Best validation accuracy: {best_val_acc:.3f} (epoch {best_epoch})")
  print(f"Final validation accuracy: {val_acc:.3f}")
  print(f"Total training time: {sum(training_history['epoch_times']):.1f}s")
  print(f"Average epoch time: {sum(training_history['epoch_times'])/len(training_history['epoch_times']):.1f}s")
  
  # Print per-category performance
  print(f"\nPer-category validation performance:")
  for category, stats in category_accuracies.items():
      print(f"  {category}: {stats['accuracy']:.3f} ({stats['correct']}/{stats['total']})")

  print(f"\nModel artifacts saved to: {output_dir}")
  print(f"  - Best model: phase1_best.pt")
  print(f"  - Final model: phase1_final.pt")
  print(f"  - Training history: training_history.json")
  print(f"  - Training config: training_config.json")

requirements:
  - torch>=1.12.0
  - torchvision>=0.13.0
  - matplotlib
  - numpy

tags:
  - training
  - resnet
  - computer-vision
  - phase1
  - category-classification
  - mixed-precision
  - mlops

version: "1.0.0"